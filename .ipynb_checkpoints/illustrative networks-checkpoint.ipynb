{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def mergeExpertise(dict1, dict2):\n",
    "    dict3 = {**dict1, **dict2}\n",
    "    for key, value in dict3.items():\n",
    "        if key in dict1 and key in dict2:\n",
    "               dict3[key] = value + dict1[key]\n",
    "    return dict3\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "    \n",
    "def expertise_paper_update(author_expertise2update,author_expertise_in_paper,author_id_li):\n",
    "    i = 0\n",
    "    for author in author_id_li:\n",
    "        if author in author_expertise2update.keys():\n",
    "            author_expertise2update[author] += author_expertise_in_paper[i]\n",
    "        else:\n",
    "             author_expertise2update[author] = author_expertise_in_paper[i]\n",
    "        i+= 1\n",
    "\n",
    "def get_M_update(df_T,reverse_mesh_dic,mesh_dic):       \n",
    "\n",
    "    df_all = df_T\n",
    "    \n",
    "    df_PM_all = df_all[df_all[2]== 'PM'].copy()\n",
    "\n",
    "    Paper1 =  df_PM_all[0]\n",
    "    Paper1 = set(Paper1)\n",
    "     \n",
    "    df_AP_all = df_all[df_all[2]== 'AP'].copy()\n",
    "    Author =  df_AP_all[0]\n",
    "    Author  = set(Author)\n",
    "    \n",
    "    Paper2 = df_AP_all[1]\n",
    "    Paper2 = set(Paper2)\n",
    "    Paper = Paper1.union(Paper2)\n",
    "\n",
    "    paper_dic = {}\n",
    "    reverse_paper_dic = {}\n",
    "    for index,value in enumerate(Paper):\n",
    "        paper_dic[index] = value\n",
    "        reverse_paper_dic[value] = index\n",
    "    \n",
    "    author_dic = {}\n",
    "    reverse_author_dic ={}\n",
    "    for index,value in enumerate(Author):\n",
    "        author_dic[index] = value\n",
    "        reverse_author_dic[value] = index\n",
    "            \n",
    "#  index conversion\n",
    "#  AP will be pre and T seperately for M_experience and M_update\n",
    "#  PM will be global one as nothing will change\n",
    "\n",
    "\n",
    "    df_tmp_T = df_T.copy()\n",
    "    df_AP_T = df_tmp_T[df_tmp_T[2]== 'AP'].copy()\n",
    "    \n",
    "    df_AP_T['paper_index'] = df_AP_T[1].astype(str).apply(lambda x: reverse_paper_dic[x])\n",
    "    df_AP_T['author_index'] = df_AP_T[0].apply(lambda x: reverse_author_dic[x])\n",
    "\n",
    "    \n",
    "    del df_AP_T[0]\n",
    "    del df_AP_T[1]\n",
    "\n",
    "    total_papers = len(Paper)\n",
    "    total_authors = len(Author)\n",
    "    \n",
    "    rows = list(df_AP_T['author_index'])\n",
    "    cols = list(df_AP_T['paper_index'])\n",
    "    \n",
    "    data_lenth = len(df_AP_T)\n",
    "    data = [1] * data_lenth\n",
    "    \n",
    "    M_update = csr_matrix((data, (rows, cols)), shape=(total_authors, total_papers))\n",
    "    \n",
    "    df_PM_all['paper_index'] = df_PM_all[0].astype(str).apply(lambda x: reverse_paper_dic[x])\n",
    "\n",
    "    df_PM_all['mesh_index'] = df_PM_all[1].apply(lambda x: reverse_mesh_dic[x])\n",
    "\n",
    "    rows = list(df_PM_all['mesh_index'])\n",
    "    cols = list(df_PM_all['paper_index'])\n",
    "    \n",
    "    data_lenth = len(df_PM_all)\n",
    "    total_mesh = len(mesh_dic)\n",
    "\n",
    "    data = [1] * data_lenth\n",
    "\n",
    "    M_mp = csr_matrix((data, (rows, cols)), shape=(total_mesh, total_papers))\n",
    "\n",
    "    return M_update.astype(bool),M_mp.astype(bool),author_dic,paper_dic,reverse_author_dic,reverse_paper_dic\n",
    "\n",
    "def SHS_Alloc(M_update,M_mp,author_dic,author_expertise):\n",
    "    author_expertise2update = dict()\n",
    "    \n",
    "    M_pa = M_update.T.tocsr() \n",
    "    M_pm = M_mp.T.tocsr() \n",
    "    ind = 0\n",
    "    \n",
    "    for paper_id in set(M_update.indices):\n",
    "        \n",
    "#         if ind%5000 == 0:\n",
    "#             print(str(ind) + 'papers processed')\n",
    "        ind +=1    \n",
    "        \n",
    "        co_authors = M_pa[paper_id,:].indices \n",
    "        mesh_in_paper = M_pm[paper_id,:].indices\n",
    "        author_expertise_in_paper = np.zeros((len(co_authors),118))\n",
    "        author_id_li = []\n",
    "        author_paper_li = []\n",
    "        for author in co_authors:\n",
    "            author_id = author_dic[author]\n",
    "            if author_id in author_expertise.keys():\n",
    "                author_paper = np.array(author_expertise[author_id])\n",
    "                author_paper = np.sqrt(sum(author_paper*author_paper) + 1)\n",
    "            else:\n",
    "#                 author_expertise[author_id] = {}\n",
    "                author_paper = 1.0\n",
    "                \n",
    "            author_paper_li.append(author_paper)\n",
    "            author_id_li.append(author_id)\n",
    "        \n",
    "        author_paper_li = np.array(author_paper_li)\n",
    "        \n",
    "        # paper list of all authors\n",
    "#         for (author_id,author_paper) in zip(author_id_li,author_paper_li):\n",
    "#             author_expertise[author_id]['pc'] =  author_paper\n",
    "        \n",
    "        for mesh in mesh_in_paper:  \n",
    "            author_exp_li = []          \n",
    "            for author_id in author_id_li:                \n",
    "                # find author exprience\n",
    "                try:                    \n",
    "                    author_exp = author_expertise[author_id][mesh]\n",
    "                    #print('upadate author')\n",
    "                except(KeyError):\n",
    "                    author_exp = 0 \n",
    "                # expertise of all co-authors about the focal mesh\n",
    "                author_exp_li.append(author_exp)  \n",
    "\n",
    "\n",
    "            author_exp_li = np.array(author_exp_li)    \n",
    "\n",
    "            # here we may want to chose from L1 or L2 norm\n",
    "\n",
    "            # norm2, second denominator\n",
    "            all_exp = np.sqrt(sum(author_exp_li*author_exp_li) + 1.0)\n",
    "\n",
    "            author_update_li = (author_exp_li*author_exp_li + 1.0)/(author_paper_li * all_exp)\n",
    "            \n",
    "            # author_exp_li = author_exp_li + author_update_li\n",
    "            author_expertise_in_paper[:,mesh] += author_update_li\n",
    "            \n",
    "        expertise_paper_update(author_expertise2update,author_expertise_in_paper,author_id_li)\n",
    "            \n",
    "    return author_expertise2update\n",
    "\n",
    "def reduce_expertise(df_ae,author_li):\n",
    "    # from dict to array\n",
    "    df = df_ae\n",
    "\n",
    "    all_mesh = set(mesh_nodes[0].values)\n",
    "\n",
    "    exist_mesh = set(df.columns)\n",
    "\n",
    "    none_col = all_mesh - exist_mesh\n",
    "\n",
    "    none_col\n",
    "\n",
    "    for name in none_col:\n",
    "        df[name] = np.nan\n",
    "\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df = df.reindex(author_li)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    author_expertise_reduced = df.T.to_dict('list')\n",
    "    \n",
    "    return author_expertise_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the file path on your side\n",
    "file = open('author_expertise_'+str(1955) + '.json', 'r') \n",
    "author_expertise = json.load(file) \n",
    "file.close()\n",
    "\n",
    "file = open('simple_expertise_'+str(1955) + '.json', 'r') \n",
    "simple_expertise = json.load(file) \n",
    "file.close()\n",
    "\n",
    "mesh_nodes = pd.read_csv('mesh_node_list.csv',header = None)\n",
    "mesh_dic = mesh_nodes[0].to_dict()\n",
    "reverse_mesh_dic = {val: key for key, val in mesh_dic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expertise generated by BL model\n",
    "df_se = pd.DataFrame(simple_expertise)\n",
    "\n",
    "df_se = df_se.T\n",
    "\n",
    "# expertise generated by DHA model\n",
    "df_ae = pd.DataFrame(author_expertise)\n",
    "\n",
    "df_ae = df_ae.T\n",
    "\n",
    "# delete paper_count as we are not using it here\n",
    "del df_ae['pc']\n",
    "\n",
    "df_ae.columns = df_ae.columns.astype(int).map(mesh_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae = df_ae.fillna(0)\n",
    "df_se = df_se.fillna(0)\n",
    "\n",
    "df_se_norm = df_se.div(df_se.sum(axis=1), axis=0)\n",
    "\n",
    "df_ae_norm = df_ae.div(df_ae.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load link list in the focusing year, this file contains link list of type \"author-paper\" and \"paper-MeSH\" at the same time, the last colomn indicates the type of link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1956\n",
    "\n",
    "df_link_T = pd.read_csv(r'link_list_1956.csv',header = None,dtype = str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example in Appendix 2: pmid == '13327374'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link_T = df_link_T[(df_link_T[1] == '13327374')|(df_link_T[0] == '13327374')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_mesh = list(df_link_T[df_link_T[0] == '13327374'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert, reorder columns, reduce raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_ae\n",
    "\n",
    "all_mesh = set(mesh_nodes[0].values)\n",
    "\n",
    "exist_mesh = set(df.columns)\n",
    "\n",
    "none_col = all_mesh - exist_mesh\n",
    "\n",
    "none_col\n",
    "\n",
    "for name in none_col:\n",
    "    df[name] = np.nan\n",
    "\n",
    "df = df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "author_li = ['18121725_3', '13327374_5', '18898073_2', '14803545_1', '18898062_1']\n",
    "\n",
    "df = df.reindex(author_li)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "author_expertise_reduced = df.T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_li = ['18121725_3', '13327374_5', '18898073_2', '14803545_1', '18898062_1']\n",
    "author_expertise_reduced = reduce_expertise(df_ae,author_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_expertise_reduced.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the method and organize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_u,Mmp,author_dic,paper_dic,reverse_author_dic,reverse_paper_dic = get_M_update(df_link_T,reverse_mesh_dic,mesh_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_expertise2update = SHS_Alloc(M_u,Mmp,author_dic,author_expertise_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(author_expertise2update).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result containing all MeSH categories, which is not easy to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the list of MeSH terms linked to this paper to reduce the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the result in Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[paper_mesh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[paper_mesh].reindex(author_li).round(3).fillna(0).to_latex('exp_added.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae.reindex(author_li)[paper_mesh].round(3).fillna(0).to_latex('author_exp.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author list:\n",
    "14803545_1: HIOCO D  D01 A12\n",
    "18898062_1: DE SEZE S B01 C05\n",
    "13327374_5: GILLE H D23 G02 G03 A12 G07 learning\n",
    "18121725_3: DELAVILLE M D06 D01\t\n",
    "18898073_2: RICHTWITZ A  B01 C19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
